# -*- coding: utf-8 -*-
import ccxt
import pandas as pd
import pandas_ta as ta
import time
# –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è datetime.strptime
from datetime import datetime
import numpy as np
import logging
import json
import os
import joblib
import glob
import re # –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç re –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π

import warnings
warnings.filterwarnings(
    "ignore",
    message="X does not have valid feature names*",
    category=UserWarning
)

# --- –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò –ü–û–°–õ–ï–î–ù–ï–ô –ú–û–î–ï–õ–ò (–ò–°–ü–†–ê–í–õ–ï–ù–û) ---
def load_latest_model():
    """
    –ò—â–µ—Ç –≤ –ø–∞–ø–∫–µ 'models' —Ñ–∞–π–ª—ã trade_model_*.pkl,
    –∏–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π.
    """
    model_dir = "models"
    pattern = "trade_model_*.pkl"
    files = glob.glob(os.path.join(model_dir, pattern))
    if not files:
        raise FileNotFoundError(f"–í –ø–∞–ø–∫–µ '{model_dir}' –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ '{pattern}'")

    latest_file = None
    latest_timestamp_dt = None # –•—Ä–∞–Ω–∏–º –æ–±—ä–µ–∫—Ç datetime –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    # –ù–∞–ø—Ä–∏–º–µ—Ä: trade_model_20250710_1441.pkl -> "20250710_1441"
    timestamp_pattern = re.compile(r"trade_model_(\d{8}_\d{4})\.pkl$")

    for f in files:
        base_name = os.path.basename(f)
        match = timestamp_pattern.search(base_name)
        if match:
            timestamp_str = match.group(1) # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–æ–∫—É –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "20250710_1441")
            try:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ –æ–±—ä–µ–∫—Ç datetime –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                current_timestamp_dt = datetime.strptime(timestamp_str, "%Y%m%d_%H%M")
                if latest_timestamp_dt is None or current_timestamp_dt > latest_timestamp_dt:
                    latest_timestamp_dt = current_timestamp_dt
                    latest_file = f
            except ValueError:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {f}. –ò–≥–Ω–æ—Ä–∏—Ä—É—é —Ñ–∞–π–ª.")
                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –≤—Ä–µ–º–µ–Ω–∏
        else:
            logger.warning(f"–ò–º—è —Ñ–∞–π–ª–∞ '{f}' –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É —à–∞–±–ª–æ–Ω—É 'trade_model_YYYYMMDD_HHMM.pkl'. –ò–≥–Ω–æ—Ä–∏—Ä—É—é —Ñ–∞–π–ª.")

    if latest_file is None:
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏ –≤ –ø–∞–ø–∫–µ '{model_dir}' –ø–æ —à–∞–±–ª–æ–Ω—É '{pattern}' —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –º–µ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏ –≤ –∏–º–µ–Ω–∏.")

    logger.info(f"üíæ –ó–∞–≥—Ä—É–∂–∞—é –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å –ø–æ –º–µ—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–∏ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {latest_file}")
    mdl = joblib.load(latest_file)
    return mdl["model"], mdl["features"]

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---
# –≠—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±—É–¥—É—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –≤ initialize_bot
model = None
features = None

# --- –ù–ê–°–¢–†–û–ô–ö–ò –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)
file_handler = logging.FileHandler('bot_log.log', encoding='utf-8')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# --- –§–ê–ô–õ–´ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –ò –°–û–°–¢–û–Ø–ù–ò–Ø ---
CONFIG_FILE = 'config.json'
STATE_FILE = 'bot_state.json'

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –ò–ó –ö–û–ù–§–ò–ì–ê ---
SYMBOLS = []
TIMEFRAME = '5m'
MONITORING_INTERVAL_SECONDS = 60
MIN_SIGNAL_STRENGTH = 3 # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
FILTER_THRESHOLD = 0.6 # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
EXCHANGE = None
active_trades = {}  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–¥–µ–ª–æ–∫

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–¢–ï–ì–ò–ò ---
ATR_LENGTH = 14
MACD_FAST_LENGTH = 12
MACD_SLOW_LENGTH = 26
MACD_SIGNAL_LENGTH = 9
BB_LENGTH = 20
BB_MULTIPLIER = 2.0
BBW_EMA_LENGTH = 20
BBW_THRESHOLD_MULTIPLIER = 1.0
VOLUME_EMA_LENGTH = 20
VOLUME_CONFIRMATION_MULTIPLIER = 1.2
RSI_REVERSAL_LONG_THRESHOLD = 45 # –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ 40
RSI_REVERSAL_SHORT_THRESHOLD = 55 # –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ 60
MACD_REVERSAL_CONFIRMATION = True
BB_MIDDLE_CROSS_ATR_BUFFER = 0.2
BBW_EMA_LENGTH = 14 # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ
VOLUME_EMA_LENGTH = 20
ADX_LENGTH = 14

# --- –ù–û–í–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ò–ù–î–ò–ö–ê–¢–û–†–û–í ---
CMF_LENGTH = 20
RVI_LENGTH = 14
KAMA_LENGTH = 10
KAMA_FAST_EMA_PERIOD = 2
KAMA_SLOW_EMA_PERIOD = 30

# --- –ö–û–ù–°–¢–ê–ù–¢–´ –î–õ–Ø –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–• SL/TP ---
LOOKBACK_CANDLES_FOR_LEVELS = 20
LEVEL_PROXIMITY_ATR_MULTIPLIER = 0.5
MIN_PROFIT_ATR_MULTIPLIER_IF_NO_LEVELS = 1.5
MIN_SL_ATR_MULTIPLIER_IF_NO_LEVELS = 1.0
MIN_SL_PERCENTAGE_OF_ENTRY = 0.005
MIN_TP_PERCENTAGE_OF_ENTRY = 0.0075
MIN_RR_RATIO_TP1 = 1.0
MIN_SL_ATR_MULTIPLIER_FLOOR = 1.5
MIN_TP_STEP_PERCENTAGE = 0.005

# --- –ò–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ ---
MACD_SUFFIX = f'_{MACD_FAST_LENGTH}_{MACD_SLOW_LENGTH}_{MACD_SIGNAL_LENGTH}'
BB_SUFFIX = f'_{BB_LENGTH}_{BB_MULTIPLIER}'


def save_state(trades_to_save):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –≤ JSON —Ñ–∞–π–ª."""
    try:
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(trades_to_save, f, indent=4)
        logger.info(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {STATE_FILE}.")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ {STATE_FILE}: {e}", exc_info=True)


def load_state():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –∏–∑ JSON —Ñ–∞–π–ª–∞, –ø—Ä–æ–≤–µ—Ä—è—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö."""
    global active_trades
    if not os.path.exists(STATE_FILE):
        logger.info(f"–§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è {STATE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é.")
        return

    try:
        with open(STATE_FILE, 'r', encoding='utf-8') as f:
            loaded_trades = json.load(f)

        clean_trades = {}
        if loaded_trades and isinstance(loaded_trades, dict):
            for symbol, trade in loaded_trades.items():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–ø–∏—Å—å —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è
                if isinstance(trade, dict) and 'type' in trade and 'entry_price' in trade:
                    clean_trades[symbol] = trade
                else:
                    logger.warning(f"   -> –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è '{symbol}'. –ó–∞–ø–∏—Å—å –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∞. –î–∞–Ω–Ω—ã–µ: {trade}")
        
        active_trades = clean_trades
        if not active_trades:
            logger.info("–§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ —Å–æ–¥–µ—Ä–∂–∞–ª –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–¥–µ–ª–æ–∫. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é.")
        else:
            logger.info(f"‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–¥–µ–ª–æ–∫: {len(active_trades)}")
            for symbol, trade in active_trades.items():
                logger.info(f"   -> –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Å–¥–µ–ª–∫–∞ –ø–æ {symbol}: {trade['type']} @ {trade['entry_price']}")

    except json.JSONDecodeError:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ {STATE_FILE}. –§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é.")
        active_trades = {}
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ {STATE_FILE}: {e}", exc_info=True)
        active_trades = {}


def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    global SYMBOLS, TIMEFRAME, MONITORING_INTERVAL_SECONDS, MIN_SIGNAL_STRENGTH, FILTER_THRESHOLD

    if not os.path.exists(CONFIG_FILE):
        logger.error(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ '{CONFIG_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–π—Ç–µ –µ–≥–æ —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.")
        default_config = {
            "symbols": ["BTC/USDT", "ETH/USDT"],
            "timeframe": "5m",
            "monitoring_interval_seconds": 60,
            "min_signal_strength": 3,
            "filter_threshold": 0.6
        }
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, indent=4)
        logger.info(f"–°–æ–∑–¥–∞–Ω –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ '{CONFIG_FILE}'. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –µ–≥–æ.")
        exit()

    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
        SYMBOLS = config.get('symbols', [])
        TIMEFRAME = config.get('timeframe', '5m')
        MONITORING_INTERVAL_SECONDS = config.get('monitoring_interval_seconds', 60)
        MIN_SIGNAL_STRENGTH = config.get('min_signal_strength', 3)
        FILTER_THRESHOLD = config.get('filter_threshold', 0.6) # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Ä–æ–≥ ML-—Ñ–∏–ª—å—Ç—Ä–∞

        if not SYMBOLS:
            logger.error(f"–°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –≤ '{CONFIG_FILE}' –ø—É—Å—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            exit()

        logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –≤—Ö–æ–¥–∞: {MIN_SIGNAL_STRENGTH}, –ü–æ—Ä–æ–≥ ML-—Ñ–∏–ª—å—Ç—Ä–∞: {FILTER_THRESHOLD}")
    except json.JSONDecodeError as e:
        logger.critical(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ '{CONFIG_FILE}': {e}", exc_info=True)
        exit()
    except Exception as e:
        logger.critical(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ '{CONFIG_FILE}': {e}", exc_info=True)
        exit()


def retry_on_exception(func, retries=3, delay=1, backoff=2):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π."""
    for i in range(retries):
        try:
            return func()
        except (ccxt.NetworkError, ccxt.ExchangeNotAvailable, ccxt.RequestTimeout, ccxt.DDoSProtection, ccxt.ExchangeError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –±–∏—Ä–∂–∏ (–ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries}): {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay:.1f} —Å–µ–∫...")
            time.sleep(delay)
            delay *= backoff
        except Exception as e:
            logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries}): {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay:.1f} —Å–µ–∫...", exc_info=True)
            time.sleep(delay)
            delay *= backoff
    raise Exception(f"–í—Å–µ {retries} –ø–æ–ø—ã—Ç–æ–∫ –∏—Å—á–µ—Ä–ø–∞–Ω—ã. –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é {func.__name__}.")


def fetch_data(symbol):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (—Å–≤–µ—á–∏) –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞—Ä—ã —Å –±–∏—Ä–∂–∏."""
    def _fetch():
        ohlcv = EXCHANGE.fetch_ohlcv(symbol, TIMEFRAME, limit=5000)
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].astype(float)
        return df

    try:
        return retry_on_exception(_fetch, retries=5, delay=2)
    except Exception as e:
        logger.critical(f"[{symbol}] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}", exc_info=True)
        return None


def calculate_atr_manually(df, length=14):
    """–†–∞—Å—á–µ—Ç Average True Range (ATR) –≤—Ä—É—á–Ω—É—é."""
    if len(df) < length + 1:
        df[f'ATR_{length}'] = np.nan
        return df
    high_low = df['high'] - df['low']
    high_close = np.abs(df['high'] - df['close'].shift())
    low_close = np.abs(df['low'] - df['close'].shift())
    tr = pd.DataFrame({'hl': high_low, 'hc': high_close, 'lc': low_close}).max(axis=1)
    df[f'ATR_{length}'] = tr.ewm(span=length, adjust=False).mean()
    return df


def add_indicators(df, symbol):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ DataFrame."""
    if df.empty:
        print(f"[{symbol}] –í—Ö–æ–¥–Ω–æ–π DataFrame –ø—É—Å—Ç. –í–æ–∑–≤—Ä–∞—â–∞—é –ø—É—Å—Ç–æ–π DF.")
        return df

    df_copy = df.copy()
    
    # 1. –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ 'timestamp' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —è–≤–ª—è–µ—Ç—Å—è datetime
    if 'timestamp' not in df_copy.columns:
        print(f"[{symbol}] –û—à–∏–±–∫–∞: –ö–æ–ª–æ–Ω–∫–∞ 'timestamp' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DataFrame. –ù–µ –º–æ–≥—É —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å DatetimeIndex.")
        return pd.DataFrame()
    
    df_copy['timestamp'] = pd.to_datetime(df_copy['timestamp'], unit='ms', errors='coerce')
    df_copy.dropna(subset=['timestamp'], inplace=True)
    if df_copy.empty:
        print(f"[{symbol}] WARNING: DataFrame –ø—É—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫.")
        return pd.DataFrame()

    # 2. –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫ float –∏ —É–¥–∞–ª—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏
    for col in ['open', 'high', 'low', 'close', 'volume']:
        if col in df_copy.columns:
            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∑–∞–º–µ–Ω–µ–Ω–æ inplace=True –Ω–∞ –ø—Ä—è–º–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ
            df_copy[col] = df_copy[col].replace([np.inf, -np.inf], np.nan)
            
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ NaNs –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤
    df_copy.dropna(subset=['open', 'high', 'low', 'close', 'volume'], inplace=True)
    if df_copy.empty:
        print(f"[{symbol}] WARNING: DataFrame –ø—É—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö OHLCV –¥–∞–Ω–Ω—ã—Ö.")
        return pd.DataFrame()

    # 3. –£—Å—Ç–∞–Ω–æ–≤–∏–º 'timestamp' –∫–∞–∫ –∏–Ω–¥–µ–∫—Å DataFrame –∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º
    df_copy.set_index('timestamp', inplace=True)
    df_copy.sort_index(inplace=True) 

    required_cols = ['open', 'high', 'low', 'close', 'volume']
    if not all(col in df_copy.columns for col in required_cols):
        print(f"[{symbol}] –û—à–∏–±–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ ({', '.join(required_cols)}) –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤.")
        df_copy.reset_index(inplace=True, drop=False)
        return pd.DataFrame()

    # --- –†–ê–°–ß–ï–¢ –ò–ù–î–ò–ö–ê–¢–û–†–û–í ---

    # ATR (—Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é)
    df_copy = calculate_atr_manually(df_copy, length=ATR_LENGTH)

    # EMA
    df_copy.ta.ema(length=50, append=True, col_names=(f'EMA_50',))
    df_copy.ta.ema(length=200, append=True, col_names=(f'EMA_200',))
    # RSI
    df_copy.ta.rsi(length=14, append=True, col_names=(f'RSI_14',))
    # MACD
    df_copy.ta.macd(fast=MACD_FAST_LENGTH, slow=MACD_SLOW_LENGTH, signal=MACD_SIGNAL_LENGTH, append=True)
    # Bollinger Bands
    df_copy.ta.bbands(length=BB_LENGTH, std=BB_MULTIPLIER, append=True)
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ BBands
    bb_upper_col = f'BBU_{BB_LENGTH}_{BB_MULTIPLIER}'
    bb_middle_col = f'BBM_{BB_LENGTH}_{BB_MULTIPLIER}'
    bb_lower_col = f'BBL_{BB_LENGTH}_{BB_MULTIPLIER}'
    
    if all(col in df_copy.columns for col in [bb_upper_col, bb_middle_col, bb_lower_col]):
        df_copy.rename(columns={
            bb_upper_col: 'BB_upper',
            bb_middle_col: 'BB_middle',
            bb_lower_col: 'BB_lower'
        }, inplace=True)
    else:
        print(f"[{symbol}] WARNING: –ù–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ BBands –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è.")
        for col in ['BB_upper', 'BB_middle', 'BB_lower']:
            if col not in df_copy.columns:
                df_copy[col] = np.nan

    # –†–∞—Å—á–µ—Ç BB_width
    df_copy['BB_width'] = (df_copy['BB_upper'] - df_copy['BB_lower']) / df_copy['BB_middle'].replace(0, np.nan)
    df_copy['BB_width'] = df_copy['BB_width'].replace([np.inf, -np.inf], np.nan)

    # BBW EMA
    bbw_col_name = 'BB_width' 
    bbw_ema_col_name = f'BBW_EMA_{BBW_EMA_LENGTH}'
    if bbw_col_name in df_copy.columns and not df_copy[bbw_col_name].isnull().all():
        df_copy[bbw_ema_col_name] = df_copy[bbw_col_name].ewm(span=BBW_EMA_LENGTH, adjust=False).mean()
    else:
        print(f"[{symbol}] WARNING: 'BB_width' –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ BBW_EMA. –ö–æ–ª–æ–Ω–∫–∞ '{bbw_ema_col_name}' –±—É–¥–µ—Ç NaN.")
        df_copy[bbw_ema_col_name] = np.nan # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    # Volume EMA
    volume_ema_col_name = 'VOLUME_EMA' 
    if 'volume' in df_copy.columns and not df_copy['volume'].isnull().all():
        df_copy[volume_ema_col_name] = df_copy['volume'].ewm(span=VOLUME_EMA_LENGTH, adjust=False).mean()
    else:
        print(f"[{symbol}] WARNING: 'volume' –∫–æ–ª–æ–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–∞. –ù–µ –º–æ–≥—É —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å VOLUME_EMA.")
        df_copy[volume_ema_col_name] = np.nan # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    
    # Chaikin Money Flow (CMF)
    if 'volume' in df_copy.columns and not (df_copy['volume'].isnull().all() or (df_copy['volume'] == 0).all()):
        df_copy.ta.cmf(length=CMF_LENGTH, append=True, col_names=(f'CMF_{CMF_LENGTH}',))
    else:
        print(f"[{symbol}] WARNING: –û–±—ä–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —Ä–∞–≤–µ–Ω –Ω—É–ª—é, CMF –Ω–µ –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.")
        
    cmf_col = f'CMF_{CMF_LENGTH}'
    if cmf_col not in df_copy.columns:
        df_copy[cmf_col] = np.nan
        print(f"[{symbol}] WARNING: –ö–æ–ª–æ–Ω–∫–∞ '{cmf_col}' –Ω–µ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ pandas_ta. –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å NaN.")
    
    # Relative Volatility Index (RVI)
    df_copy.ta.rvi(length=RVI_LENGTH, append=True, col_names=(f'RVI_{RVI_LENGTH}',))
    rvi_col = f'RVI_{RVI_LENGTH}'
    if rvi_col not in df_copy.columns:
        df_copy[rvi_col] = np.nan
        print(f"[{symbol}] WARNING: –ö–æ–ª–æ–Ω–∫–∞ '{rvi_col}' –Ω–µ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ pandas_ta. –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å NaN.")
    
    # Kaufman's Adaptive Moving Average (KAMA)
    df_copy.ta.kama(length=KAMA_LENGTH, fast=KAMA_FAST_EMA_PERIOD, slow=KAMA_SLOW_EMA_PERIOD, append=True, col_names=(f'KAMA_{KAMA_LENGTH}_{KAMA_FAST_EMA_PERIOD}_{KAMA_SLOW_EMA_PERIOD}',))
    kama_col = f'KAMA_{KAMA_LENGTH}_{KAMA_FAST_EMA_PERIOD}_{KAMA_SLOW_EMA_PERIOD}'
    if kama_col not in df_copy.columns:
        df_copy[kama_col] = np.nan
        print(f"[{symbol}] WARNING: –ö–æ–ª–æ–Ω–∫–∞ '{kama_col}' –Ω–µ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ pandas_ta. –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å NaN.")

    # # Stochastic Oscillator (STOCH) - –£–î–ê–õ–ï–ù–û
    # # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–∞—Ä–∏–∞—Ü–∏–∏ –≤ high/low, –∏–Ω–∞—á–µ Stoch –±—É–¥–µ—Ç NaN
    # if (df_copy['high'] == df_copy['low']).all():
    #     print(f"[{symbol}] WARNING: –¶–µ–Ω—ã –Ω–µ –º–µ–Ω—è—é—Ç—Å—è (High == Low). –°—Ç–æ—Ö–∞—Å—Ç–∏–∫ –Ω–µ –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.")
    #     df_copy['STOCH_k'] = np.nan
    #     df_copy['STOCH_d'] = np.nan
    # else:
    #     df_copy.ta.stoch(k=STOCH_K_LENGTH, d=STOCH_D_LENGTH, append=True)
    #     stoch_k_col_name = f'STOCHk_{STOCH_K_LENGTH}_{STOCH_D_LENGTH}'
    #     stoch_d_col_name = f'STOCHd_{STOCH_K_LENGTH}_{STOCH_D_LENGTH}'
    #     if stoch_k_col_name in df_copy.columns and stoch_d_col_name in df_copy.columns:
    #         df_copy.rename(columns={stoch_k_col_name: 'STOCH_k', stoch_d_col_name: 'STOCH_d'}, inplace=True)
    #     else:
    #         print(f"[{symbol}] WARNING: –°—Ç–æ—Ö–∞—Å—Ç–∏–∫ ({stoch_k_col_name}, {stoch_d_col_name}) –Ω–µ –±—ã–ª —Ä–∞—Å—Å—á–∏—Ç–∞–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö.")
    #         df_copy['STOCH_k'] = np.nan
    #         df_copy['STOCH_d'] = np.nan
    
    # Average Directional Index (ADX)
    df_copy.ta.adx(length=ADX_LENGTH, append=True)
    adx_col_name = f'ADX_{ADX_LENGTH}'
    if adx_col_name in df_copy.columns:
        df_copy.rename(columns={adx_col_name: 'ADX_14'}, inplace=True)
    else:
        print(f"[{symbol}] WARNING: ADX ({adx_col_name}) –Ω–µ –±—ã–ª —Ä–∞—Å—Å—á–∏—Ç–∞–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö.")
        df_copy['ADX_14'] = np.nan

    # # Commodity Channel Index (CCI) - –£–î–ê–õ–ï–ù–û
    # # CCI —Ç–∞–∫–∂–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ "–ø–ª–æ—Å–∫–∏–º" —Å–≤–µ—á–∞–º
    # if (df_copy['high'] == df_copy['low']).all():
    #     print(f"[{symbol}] WARNING: –¶–µ–Ω—ã –Ω–µ –º–µ–Ω—è—é—Ç—Å—è (High == Low). CCI –Ω–µ –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.")
    #     df_copy['CCI_20'] = np.nan
    # else:
    #     df_copy.ta.cci(length=CCI_LENGTH, append=True)
    #     cci_col_name = f'CCI_{CCI_LENGTH}'
    #     if cci_col_name in df_copy.columns:
    #         df_copy.rename(columns={cci_col_name: 'CCI_20'}, inplace=True)
    #     else:
    #         print(f"[{symbol}] WARNING: CCI ({cci_col_name}) –Ω–µ –±—ã–ª —Ä–∞—Å—Å—á–∏—Ç–∞–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö.")
    #         df_copy['CCI_20'] = np.nan

    # # Volume Weighted Average Price (VWAP) - –£–î–ê–õ–ï–ù–û
    # # VWAP –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–±—ä–µ–º–∞.
    # if 'volume' in df_copy.columns and not (df_copy['volume'].isnull().all() or (df_copy['volume'] == 0).all()):
    #     try:
    #         df_copy.ta.vwap(append=True)
    #         df_copy.rename(columns={'VWAP': 'VWAP_14'}, inplace=True) # pandas_ta.vwap() –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç length
    #     except Exception as e:
    #         print(f"[{symbol}] WARNING: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ VWAP: {e}. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω–¥–µ–∫—Å–æ–º/–¥–∞–Ω–Ω—ã–º–∏.")
    #         df_copy['VWAP_14'] = np.nan
    # else:
    #     print(f"[{symbol}] WARNING: –û–±—ä–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —Ä–∞–≤–µ–Ω –Ω—É–ª—é, VWAP –Ω–µ –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.")
    #     if 'VWAP_14' not in df_copy.columns: # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    #         df_copy['VWAP_14'] = np.nan

    # --- –ó–ê–ü–û–õ–ù–ï–ù–ò–ï NaN –¥–ª—è –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ ---
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∑–∞–º–µ–Ω–µ–Ω–æ inplace=True –Ω–∞ –ø—Ä—è–º–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ
    for col in df_copy.columns:
        if df_copy[col].dtype == 'float64' and df_copy[col].isnull().any():
            df_copy[col] = df_copy[col].fillna(0)

    # --- –ó–ê–í–ï–†–®–ê–Æ–©–ò–ï –®–ê–ì–ò ---
    # –í–µ—Ä–Ω—É—Ç—å 'timestamp' –∫–∞–∫ –æ–±—ã—á–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
    df_copy.reset_index(inplace=True, drop=False) 

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN.
    initial_rows_before_final_dropna = len(df_copy)
    df_copy.dropna(inplace=True) 
    final_rows_after_final_dropna = len(df_copy)

    if final_rows_after_final_dropna == 0:
        print(f"[{symbol}] CRITICAL: DataFrame –ø—É—Å—Ç –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è NaN. –≠—Ç–æ —Å–µ—Ä—å–µ–∑–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏.")
        return pd.DataFrame()
    elif final_rows_after_final_dropna < initial_rows_before_final_dropna:
        print(f"[{symbol}] WARNING: –ü–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ —É–¥–∞–ª–µ–Ω–æ {initial_rows_before_final_dropna - final_rows_after_final_dropna} —Å—Ç—Ä–æ–∫. –û—Å—Ç–∞–ª–æ—Å—å {final_rows_after_final_dropna} —Å—Ç—Ä–æ–∫.")
    #else:
        #print(f"[{symbol}] INFO: DataFrame —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω, —Å–æ–¥–µ—Ä–∂–∏—Ç {final_rows_after_final_dropna} —Å—Ç—Ä–æ–∫.")
    
    return df_copy


def find_significant_levels(df, current_price, position_type, current_atr):
    """–ò—â–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è."""
    levels = []
    if len(df) > LOOKBACK_CANDLES_FOR_LEVELS:
        recent_candles = df.iloc[-(LOOKBACK_CANDLES_FOR_LEVELS + 1):-1]
        if position_type == "LONG":
            levels.extend(recent_candles['high'].tolist())
        elif position_type == "SHORT":
            levels.extend(recent_candles['low'].tolist())
    last_candle = df.iloc[-1]
    if not pd.isna(last_candle['BB_upper']): # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        levels.append(last_candle['BB_upper'])
    if not pd.isna(last_candle['BB_lower']): # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        levels.append(last_candle['BB_lower'])
    if not pd.isna(last_candle['EMA_50']):
        levels.append(last_candle['EMA_50'])
    if not pd.isna(last_candle['EMA_200']):
        levels.append(last_candle['EMA_200'])
    levels = list(set([l for l in levels if pd.notna(l) and np.isfinite(l)]))
    if position_type == "LONG":
        tp_levels = sorted([l for l in levels if l > current_price])
        sl_levels = sorted([l for l in levels if l < current_price], reverse=True)
    else:  # SHORT
        tp_levels = sorted([l for l in levels if l < current_price], reverse=True)
        sl_levels = sorted([l for l in levels if l > current_price])
    
    filtered_tp_levels = [l for l in tp_levels if (position_type == "LONG" and l > current_price + current_atr * LEVEL_PROXIMITY_ATR_MULTIPLIER) or (position_type == "SHORT" and l < current_price - current_atr * LEVEL_PROXIMITY_ATR_MULTIPLIER)][:3]
    filtered_sl_levels = [l for l in sl_levels if (position_type == "LONG" and l < current_price - current_atr * LEVEL_PROXIMITY_ATR_MULTIPLIER) or (position_type == "SHORT" and l > current_price + current_atr * LEVEL_PROXIMITY_ATR_MULTIPLIER)][:1]
    
    return filtered_sl_levels, filtered_tp_levels
def calculate_dynamic_sl_tp(entry_price, df, position_type, symbol, signal_type="GENERIC"):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å –∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—ã —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º 
    –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é TP, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π —à–∞–≥ –¥–ª—è –¥–µ—à–µ–≤—ã—Ö –∞–∫—Ç–∏–≤–æ–≤.
    """
    last_candle = df.iloc[-1]
    current_atr = last_candle.get(f'ATR_{ATR_LENGTH}', np.nan)
    if pd.isna(current_atr) or not np.isfinite(current_atr) or current_atr <= 1e-10:
        current_atr = entry_price * 0.001
        logger.warning(f"[{symbol}] ATR –Ω–µ–≤–∞–ª–∏–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è % –æ—Ç —Ü–µ–Ω—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞.")

    sl_price = 0
    tp_prices = {}
    potential_sl_levels, potential_tp_levels = find_significant_levels(df, entry_price, position_type, current_atr)

    # --- 1. –†–∞—Å—á–µ—Ç SL –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥–∏–∫–µ ---
    if position_type == "LONG":
        if "HAMMER" in signal_type and last_candle['low'] < entry_price:
            sl_price = last_candle['low']
        elif "ENGULFING" in signal_type and df.iloc[-2]['low'] < entry_price:
            sl_price = df.iloc[-2]['low']
        elif potential_sl_levels:
            sl_candidate = potential_sl_levels[0]
            sl_price = sl_candidate if sl_candidate < entry_price - (current_atr * 0.1) else entry_price - (current_atr * MIN_SL_ATR_MULTIPLIER_IF_NO_LEVELS)
        else:
            sl_price = entry_price - (current_atr * MIN_SL_ATR_MULTIPLIER_IF_NO_LEVELS)
    elif position_type == "SHORT":
        if "ENGULFING" in signal_type and df.iloc[-2]['high'] > entry_price:
            sl_price = df.iloc[-2]['high']
        elif potential_sl_levels:
            sl_candidate = potential_sl_levels[0]
            sl_price = sl_candidate if sl_candidate > entry_price + (current_atr * 0.1) else entry_price + (current_atr * MIN_SL_ATR_MULTIPLIER_IF_NO_LEVELS)
        else:
            sl_price = entry_price + (current_atr * MIN_SL_ATR_MULTIPLIER_IF_NO_LEVELS)

    # --- 2. –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è SL ---
    min_sl_dist_percent = entry_price * MIN_SL_PERCENTAGE_OF_ENTRY
    min_sl_dist_atr = current_atr * MIN_SL_ATR_MULTIPLIER_FLOOR
    final_min_dist = max(min_sl_dist_percent, min_sl_dist_atr)

    if position_type == "LONG":
        guaranteed_sl = entry_price - final_min_dist
        sl_price = min(sl_price, guaranteed_sl)
    elif position_type == "SHORT":
        guaranteed_sl = entry_price + final_min_dist
        sl_price = max(sl_price, guaranteed_sl)

    # --- 3. –ü–µ—Ä–≤–∏—á–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ TP ---
    if potential_tp_levels:
        tp_prices['TP1'] = potential_tp_levels[0] if len(potential_tp_levels) > 0 else None
        tp_prices['TP2'] = potential_tp_levels[1] if len(potential_tp_levels) > 1 else None
        tp_prices['TP3'] = potential_tp_levels[2] if len(potential_tp_levels) > 2 else None
    
    # --- 4. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ TP1 –¥–ª—è R:R ---
    risk_distance = abs(entry_price - sl_price)
    reward_distance_tp1 = abs(tp_prices.get('TP1', entry_price) - entry_price) if tp_prices.get('TP1') else 0
    if risk_distance > 1e-10 and reward_distance_tp1 < risk_distance * MIN_RR_RATIO_TP1:
        logger.warning(f"[{symbol}] TP1 —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è R:R > {MIN_RR_RATIO_TP1}")
        if position_type == "LONG":
            tp_prices['TP1'] = entry_price + (risk_distance * MIN_RR_RATIO_TP1)
        else:
            tp_prices['TP1'] = entry_price - (risk_distance * MIN_RR_RATIO_TP1)
            
    # --- 5. –ö–∞—Å–∫–∞–¥–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç TP —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–≥–æ —à–∞–≥–∞ ---
    atr_based_step = current_atr * (MIN_PROFIT_ATR_MULTIPLIER_IF_NO_LEVELS / 2)
    percent_based_step = entry_price * MIN_TP_STEP_PERCENTAGE
    
    final_tp_step = max(atr_based_step, percent_based_step)
    logger.info(f"[{symbol}] –®–∞–≥ –¥–ª—è TP –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ {final_tp_step:.8f} (ATR_step: {atr_based_step:.8f}, Percent_step: {percent_based_step:.8f})")

    if position_type == "LONG":
        if not tp_prices.get('TP1'):
            min_tp1_price = entry_price + (entry_price * MIN_TP_PERCENTAGE_OF_ENTRY)
            tp_prices['TP1'] = max(min_tp1_price, entry_price + (current_atr * MIN_PROFIT_ATR_MULTIPLIER_IF_NO_LEVELS))
        
        if not tp_prices.get('TP2') or tp_prices.get('TP2') <= tp_prices.get('TP1'):
            tp_prices['TP2'] = tp_prices.get('TP1') + final_tp_step
        
        if not tp_prices.get('TP3') or tp_prices.get('TP3') <= tp_prices.get('TP2'):
            tp_prices['TP3'] = tp_prices.get('TP2') + final_tp_step
    
    elif position_type == "SHORT":
        if not tp_prices.get('TP1'):
            min_tp1_price = entry_price - (entry_price * MIN_TP_PERCENTAGE_OF_ENTRY)
            tp_prices['TP1'] = min(min_tp1_price, entry_price - (current_atr * MIN_PROFIT_ATR_MULTIPLIER_IF_NO_LEVELS))

        if not tp_prices.get('TP2') or tp_prices.get('TP2') >= tp_prices.get('TP1'):
            tp_prices['TP2'] = tp_prices.get('TP1') - final_tp_step
        
        if not tp_prices.get('TP3') or tp_prices.get('TP3') >= tp_prices.get('TP2'):
            tp_prices['TP3'] = tp_prices.get('TP2') - final_tp_step

    return sl_price, tp_prices


def check_hammer_candlestick(df):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –ú–æ–ª–æ—Ç (Hammer) –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–µ."""
    if len(df) < 1: return False
    last_candle = df.iloc[-1]
    body = abs(last_candle['open'] - last_candle['close'])
    lower_shadow = min(last_candle['open'], last_candle['close']) - last_candle['low']
    upper_shadow = last_candle['high'] - max(last_candle['open'], last_candle['close'])
    candle_range = last_candle['high'] - last_candle['low']
    if candle_range < 1e-9: return False

    is_small_body = body < candle_range * 0.3
    is_long_lower_shadow = lower_shadow >= 2 * body if body > 1e-9 else True
    is_small_upper_shadow = upper_shadow <= body * 0.3 if body > 1e-9 else True
    return is_small_body and is_long_lower_shadow and is_small_upper_shadow


def check_engulfing_candlestick(df, is_bullish):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –ü–æ–≥–ª–æ—â–µ–Ω–∏–µ (Engulfing) –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–≤—É—Ö —Å–≤–µ—á–∞—Ö."""
    if len(df) < 2: return False
    last_candle = df.iloc[-1]
    prev_candle = df.iloc[-2]
    if is_bullish:
        is_prev_bearish = prev_candle['close'] < prev_candle['open']
        is_curr_bullish = last_candle['close'] > last_candle['open']
        is_engulfing = (last_candle['open'] <= prev_candle['close'] and last_candle['close'] >= prev_candle['open'])
        return is_prev_bearish and is_curr_bullish and is_engulfing
    else:  # is_bearish
        is_prev_bullish = prev_candle['close'] > prev_candle['open']
        is_curr_bearish = last_candle['close'] < last_candle['open']
        is_engulfing = (last_candle['open'] >= prev_candle['close'] and last_candle['close'] <= prev_candle['open'])
        return is_prev_bullish and is_curr_bearish and is_engulfing


def is_bollinger_bands_squeezing(df, current_bbw, bbw_ema):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥—è—Ç—Å—è –ª–∏ –ø–æ–ª–æ—Å—ã –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∂–∞—Ç–∏—è."""
    return current_bbw < bbw_ema * BBW_THRESHOLD_MULTIPLIER

# --- –§—É–Ω–∫—Ü–∏—è ML-—Ñ–∏–ª—å—Ç—Ä–∞ ---
def filter_signal(candle_dict: dict) -> float:
    # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ 'features' –∏ 'model' –¥–æ—Å—Ç—É–ø–Ω—ã –≥–ª–æ–±–∞–ª—å–Ω–æ
    global features, model

    if model is None or features is None:
        logger.error("ML –º–æ–¥–µ–ª—å –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
        return 0.0 # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 0, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞

    feat_vector = []
    for f in features:
        if f not in candle_dict:
            logger.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫ '{f}' –¥–ª—è ML-–º–æ–¥–µ–ª–∏. –í–æ–∑–≤—Ä–∞—â–∞—é 0.00.")
            return 0.0 # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        feat_vector.append(candle_dict[f])

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º predict_proba –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ 1 (–ø—Ä–∏–±—ã–ª—å–Ω–æ–π —Å–¥–µ–ª–∫–∏)
    prob = model.predict_proba([feat_vector])[:, 1][0]
    return prob


def analyze_data(symbol, df):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏, –µ—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–ª—å–Ω—ã–π, –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç —Å–¥–µ–ª–∫—É."""
    last_candle = df.iloc[-1]
    prev_candle = df.iloc[-2]
    current_close_price = last_candle['close']

    long_score, short_score = 0, 0
    long_signal_reasons, short_signal_reasons = [], []
    signal_type_long, signal_type_short = "GENERIC_LONG", "GENERIC_SHORT" # –ò–∑–º–µ–Ω–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–µ–π —è—Å–Ω–æ—Å—Ç–∏

    # --- –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ---
    if (prev_candle[f'MACD{MACD_SUFFIX}'] < prev_candle[f'MACDs{MACD_SUFFIX}'] and last_candle[f'MACD{MACD_SUFFIX}'] > last_candle[f'MACDs{MACD_SUFFIX}']):
        long_score += 1
        long_signal_reasons.append("MACD –∫—Ä–æ—Å—Å–æ–≤–µ—Ä –≤–≤–µ—Ä—Ö")
    if (prev_candle[f'MACD{MACD_SUFFIX}'] > prev_candle[f'MACDs{MACD_SUFFIX}'] and last_candle[f'MACD{MACD_SUFFIX}'] < last_candle[f'MACDs{MACD_SUFFIX}']):
        short_score += 1
        short_signal_reasons.append("MACD –∫—Ä–æ—Å—Å–æ–≤–µ—Ä –≤–Ω–∏–∑")
    
    if (prev_candle['RSI_14'] < 30 and last_candle['RSI_14'] > 30):
        long_score += 1
        long_signal_reasons.append(f"RSI –≤—ã—Ö–æ–¥ –∏–∑ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏ ({last_candle['RSI_14']:.2f})")
    if (prev_candle['RSI_14'] > 70 and last_candle['RSI_14'] < 70):
        short_score += 1
        short_signal_reasons.append(f"RSI –≤—ã—Ö–æ–¥ –∏–∑ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç–∏ ({last_candle['RSI_14']:.2f})")
    
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ KAMA –≤–º–µ—Å—Ç–æ EMA 50/200 –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
    kama_col_name = f'KAMA_{KAMA_LENGTH}_{KAMA_FAST_EMA_PERIOD}_{KAMA_SLOW_EMA_PERIOD}'
    if kama_col_name in last_candle:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ –ø–æ KAMA
        if current_close_price > last_candle[kama_col_name] and last_candle[kama_col_name] > df.iloc[-2][kama_col_name]: # –¶–µ–Ω–∞ –≤—ã—à–µ KAMA –∏ KAMA —Ä–∞—Å—Ç–µ—Ç
            long_score += 1
            long_signal_reasons.append("–í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ –ø–æ KAMA")
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ –ø–æ KAMA
        if current_close_price < last_candle[kama_col_name] and last_candle[kama_col_name] < df.iloc[-2][kama_col_name]: # –¶–µ–Ω–∞ –Ω–∏–∂–µ KAMA –∏ KAMA –ø–∞–¥–∞–µ—Ç
            short_score += 1
            short_signal_reasons.append("–ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ –ø–æ KAMA")
    else: # –ï—Å–ª–∏ KAMA –ø–æ –∫–∞–∫–∏–º-—Ç–æ –ø—Ä–∏—á–∏–Ω–∞–º –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–µ EMA
        if (current_close_price > last_candle['EMA_50'] and last_candle['EMA_50'] > last_candle['EMA_200']):
            long_score += 1
            long_signal_reasons.append("–°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (EMA)")
        if (current_close_price < last_candle['EMA_50'] and last_candle['EMA_50'] < last_candle['EMA_200']):
            short_score += 1
            short_signal_reasons.append("–°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (EMA)")

    bbw_col_name = 'BB_width' # –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
    bbw_ema_col_name = f'BBW_EMA_{BBW_EMA_LENGTH}'
    if bbw_col_name in last_candle and bbw_ema_col_name in last_candle and is_bollinger_bands_squeezing(df, last_candle[bbw_col_name], last_candle[bbw_ema_col_name]):
        long_score += 1
        short_score += 1
        long_signal_reasons.append("BB Squeeze")
        short_signal_reasons.append("BB Squeeze")
    
    # VOLUME_EMA - —Ç–µ–ø–µ—Ä—å –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞, –∫–∞–∫ –≤ feature_engineering.py
    if last_candle['volume'] > (last_candle['VOLUME_EMA'] * VOLUME_CONFIRMATION_MULTIPLIER):
        long_score += 1
        short_score += 1
        long_signal_reasons.append("–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –æ–±—ä–µ–º")
        short_signal_reasons.append("–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –æ–±—ä–µ–º")

    # --- –ù–û–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ –ò –õ–û–ì–ò–ö–ê ---
    # Chaikin Money Flow (CMF)
    cmf_col_name = f'CMF_{CMF_LENGTH}'
    if cmf_col_name in last_candle:
        # –î–ª—è –ª–æ–Ω–≥–∞: CMF > 0 –∏ —Ä–∞—Å—Ç–µ—Ç –∏–ª–∏ CMF –ø–µ—Ä–µ—Å–µ–∫ 0 —Å–Ω–∏–∑—É –≤–≤–µ—Ä—Ö
        if last_candle[cmf_col_name] > 0.05 and prev_candle[cmf_col_name] <= 0.05: # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –Ω—É–ª—è —Å–Ω–∏–∑—É –≤–≤–µ—Ä—Ö –∏–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            long_score += 1
            long_signal_reasons.append(f"CMF (–ø–æ–∫—É–ø–∫–∞) ({last_candle[cmf_col_name]:.2f})")
        elif last_candle[cmf_col_name] > 0.1 and last_candle[cmf_col_name] > prev_candle[cmf_col_name]: # –£–≤–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ä–æ—Å—Ç
            long_score += 0.5
            long_signal_reasons.append(f"CMF (—Å–∏–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∫—É–ø–∫–∏) ({last_candle[cmf_col_name]:.2f})")

        # –î–ª—è —à–æ—Ä—Ç–∞: CMF < 0 –∏ –ø–∞–¥–∞–µ—Ç –∏–ª–∏ CMF –ø–µ—Ä–µ—Å–µ–∫ 0 —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑
        if last_candle[cmf_col_name] < -0.05 and prev_candle[cmf_col_name] >= -0.05: # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –Ω—É–ª—è —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑ –∏–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            short_score += 1
            short_signal_reasons.append(f"CMF (–ø—Ä–æ–¥–∞–∂–∞) ({last_candle[cmf_col_name]:.2f})")
        elif last_candle[cmf_col_name] < -0.1 and last_candle[cmf_col_name] < prev_candle[cmf_col_name]: # –£–≤–µ—Ä–µ–Ω–Ω–æ–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏ –ø–∞–¥–µ–Ω–∏–µ
            short_score += 0.5
            short_signal_reasons.append(f"CMF (—Å–∏–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∏) ({last_candle[cmf_col_name]:.2f})")
    
    # --- –°–≤–µ—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã ---
    if current_close_price < last_candle['EMA_50']: # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ª–æ–Ω–≥–∞ —á–∞—â–µ –∏—â—É—Ç –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏/–ø–∞–¥–µ–Ω–∏–∏
        if check_hammer_candlestick(df):
            long_score += 2
            long_signal_reasons.append("–ü–∞—Ç—Ç–µ—Ä–Ω: –ú–æ–ª–æ—Ç")
            signal_type_long += "_HAMMER"
        if check_engulfing_candlestick(df, is_bullish=True):
            long_score += 2
            long_signal_reasons.append("–ü–∞—Ç—Ç–µ—Ä–Ω: –ë—ã—á—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ")
            signal_type_long += "_ENGULFING"
    
    if current_close_price > last_candle['EMA_50']: # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —à–æ—Ä—Ç–∞ —á–∞—â–µ –∏—â—É—Ç –Ω–∞ —Ä–æ—Å—Ç–µ/–≤–µ—Ä—à–∏–Ω–µ
        if check_engulfing_candlestick(df, is_bullish=False):
            short_score += 2
            short_signal_reasons.append("–ü–∞—Ç—Ç–µ—Ä–Ω: –ú–µ–¥–≤–µ–∂—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ")
            signal_type_short += "_ENGULFING"
            
    # --- –û—Ç–∫—Ä—ã—Ç–∏–µ —Å–¥–µ–ª–∫–∏ ---
    if long_score >= MIN_SIGNAL_STRENGTH:
        # ‚ñ∂ ML-—Ñ–∏–ª—å—Ç—Ä
        prob = filter_signal(last_candle.to_dict())
        if prob < FILTER_THRESHOLD:
            logger.info(f"[{symbol}] ML-—Ñ–∏–ª—å—Ç—Ä –æ—Ç–∫–ª–æ–Ω–∏–ª LONG (prob={prob:.2f} < {FILTER_THRESHOLD})")
            return
        
        sl, tps = calculate_dynamic_sl_tp(current_close_price, df, "LONG", symbol, signal_type_long)
        active_trades[symbol] = {"type": "LONG", "entry_price": current_close_price, "sl": sl, "tp1": tps.get('TP1'), "tp2": tps.get('TP2'), "tp3": tps.get('TP3'), "status": "active"}
        logger.info(f"‚úÖ [{symbol}] –û–¢–ö–†–´–¢–ê LONG –°–î–ï–õ–ö–ê (–°–∏–ª–∞: {long_score}, ML-Prob: {prob:.2f}) @ {current_close_price:.8f}")
        logger.info(f"   SL: {sl:.8f}, TP1: {tps.get('TP1', 0.0):.8f}, TP2: {tps.get('TP2', 0.0):.8f}, TP3: {tps.get('TP3', 0.0):.8f}")
        logger.info(f"   –ü—Ä–∏—á–∏–Ω—ã: {'; '.join(long_signal_reasons)}")
        save_state(active_trades)

    elif short_score >= MIN_SIGNAL_STRENGTH:
        # ‚ñ∂ ML-—Ñ–∏–ª—å—Ç—Ä
        prob = filter_signal(last_candle.to_dict())
        if prob < FILTER_THRESHOLD:
            logger.info(f"[{symbol}] ML-—Ñ–∏–ª—å—Ç—Ä –æ—Ç–∫–ª–æ–Ω–∏–ª SHORT (prob={prob:.2f} < {FILTER_THRESHOLD})")
            return

        sl, tps = calculate_dynamic_sl_tp(current_close_price, df, "SHORT", symbol, signal_type_short)
        active_trades[symbol] = {"type": "SHORT", "entry_price": current_close_price, "sl": sl, "tp1": tps.get('TP1'), "tp2": tps.get('TP2'), "tp3": tps.get('TP3'), "status": "active"}
        logger.info(f"‚úÖ [{symbol}] –û–¢–ö–†–´–¢–ê SHORT –°–î–ï–õ–ö–ê (–°–∏–ª–∞: {short_score}, ML-Prob: {prob:.2f}) @ {current_close_price:.8f}")
        logger.info(f"   SL: {sl:.8f}, TP1: {tps.get('TP1', 0.0):.8f}, TP2: {tps.get('TP2', 0.0):.8f}, TP3: {tps.get('TP3', 0.0):.8f}")
        logger.info(f"   –ü—Ä–∏—á–∏–Ω—ã: {'; '.join(short_signal_reasons)}")
        save_state(active_trades)


def monitor_trade(symbol, df):
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—É—é —Å–¥–µ–ª–∫—É, –ø—Ä–æ–≤–µ—Ä—è—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ SL/TP."""
    global active_trades
    trade = active_trades[symbol]
    current_price = df.iloc[-1]['close']
    trade_type = trade['type']
    status = trade['status']
    sl, tp1, tp2, tp3 = trade['sl'], trade['tp1'], trade['tp2'], trade['tp3']

    logger.info(f"üëÄ [{symbol}] –û—Ç—Å–ª–µ–∂–∏–≤–∞—é {trade_type} | –¶–µ–Ω–∞: {current_price:.8f} | –í—Ö–æ–¥: {trade['entry_price']:.8f} | –°—Ç–∞—Ç—É—Å: {status}")

    if trade_type == 'LONG':
        if current_price <= sl:
            logger.info(f"üõë [{symbol}] –°–î–ï–õ–ö–ê –ó–ê–ö–†–´–¢–ê –ø–æ Stop Loss @ {current_price:.8f}")
            del active_trades[symbol]
            save_state(active_trades)
            return
        if tp3 and current_price >= tp3:
            logger.info(f"üéâ [{symbol}] –°–î–ï–õ–ö–ê –ó–ê–ö–†–´–¢–ê –ø–æ Take Profit 3 @ {current_price:.8f}")
            del active_trades[symbol]
            save_state(active_trades)
            return
        if tp2 and current_price >= tp2 and status != 'tp2_hit':
            logger.info(f"üéØ [{symbol}] Take Profit 2 –¥–æ—Å—Ç–∏–≥–Ω—É—Ç @ {current_price:.8f}")
            trade['status'] = 'tp2_hit'
            save_state(active_trades)
        elif tp1 and current_price >= tp1 and status == 'active':
            logger.info(f"üéØ [{symbol}] Take Profit 1 –¥–æ—Å—Ç–∏–≥–Ω—É—Ç @ {current_price:.8f}")
            trade['status'] = 'tp1_hit'
            save_state(active_trades)

    elif trade_type == 'SHORT':
        if current_price >= sl:
            logger.info(f"üõë [{symbol}] –°–î–ï–õ–ö–ê –ó–ê–ö–†–´–¢–ê –ø–æ Stop Loss @ {current_price:.8f}")
            del active_trades[symbol]
            save_state(active_trades)
            return
        if tp3 and current_price <= tp3:
            logger.info(f"üéâ [{symbol}] –°–î–ï–õ–ö–ê –ó–ê–ö–†–´–¢–ê –ø–æ Take Profit 3 @ {current_price:.8f}")
            del active_trades[symbol]
            save_state(active_trades)
            return
        if tp2 and current_price <= tp2 and status != 'tp2_hit':
            logger.info(f"üéØ [{symbol}] Take Profit 2 –¥–æ—Å—Ç–∏–≥–Ω—É—Ç @ {current_price:.8f}")
            trade['status'] = 'tp2_hit'
            save_state(active_trades)
        elif tp1 and current_price <= tp1 and status == 'active':
            logger.info(f"üéØ [{symbol}] Take Profit 1 –¥–æ—Å—Ç–∏–≥–Ω—É—Ç @ {current_price:.8f}")
            trade['status'] = 'tp1_hit'
            save_state(active_trades)


def initialize_bot():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–æ—Ç–∞: –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥, –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –±–∏—Ä–∂–µ, –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –º–æ–¥–µ–ª—å."""
    global EXCHANGE, model, features
    load_config()
    try:
        EXCHANGE = ccxt.binanceusdm({'options': {'defaultType': 'future', 'adjustForTimeDifference': True}})
        EXCHANGE.load_markets()
        logger.info("–ë–∏—Ä–∂–∞ Binance USDT-M Futures —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")
    except Exception as e:
        logger.critical(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏—Ä–∂–∏: {e}", exc_info=True)
        exit()
    load_state()
    try:
        model, features = load_latest_model()
        logger.info("‚úÖ ML-–º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
    except Exception as e:
        logger.critical(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ ML-–º–æ–¥–µ–ª–∏: {e}. –ë–æ—Ç –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ML-—Ñ–∏–ª—å—Ç—Ä.", exc_info=True)
        model = None
        features = None


def main_loop():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞."""
    initialize_bot()
    while True:
        logger.info(f"\n--- –ù–æ–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è | –ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–æ–∫: {len(active_trades)} ---")
        for symbol in SYMBOLS:
            df = fetch_data(symbol)
            if df is None or df.empty:
                continue
            df_with_indicators = add_indicators(df, symbol)
            if df_with_indicators.empty:
                continue
            try:
                if symbol in active_trades:
                    monitor_trade(symbol, df_with_indicators)
                else:
                    analyze_data(symbol, df_with_indicators)
            except Exception as e:
                logger.error(f"[{symbol}] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}", exc_info=True)
            time.sleep(1)
        logger.info(f"--- –ò—Ç–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {MONITORING_INTERVAL_SECONDS} —Å–µ–∫—É–Ω–¥. ---")
        time.sleep(MONITORING_INTERVAL_SECONDS)


if __name__ == "__main__":
    main_loop()